# Database Schema Migration Plan
## From Multi-Table to Single-Table Design

---

## ğŸ¯ GOAL
Simplify from 4 tables to 1 unified table with status tracking

---

## ğŸ“Š CURRENT SCHEMA (Complex)

```
Tables:
â”œâ”€â”€ current_listings   (today's scrape)
â”œâ”€â”€ previous_listings  (yesterday's scrape)
â”œâ”€â”€ just_listed        (newly discovered)
â””â”€â”€ sold_listings      (disappeared)

Problems:
âŒ Data duplication
âŒ Complex diff logic
âŒ Hard to track history
âŒ Inefficient at scale
âŒ Hard to query "all active" or "all sold"
```

---

## âœ… NEW SCHEMA (Simple & Scalable)

```
Single Table: listings

Core Listing Data:
â”œâ”€â”€ zpid (PRIMARY KEY)
â”œâ”€â”€ price
â”œâ”€â”€ bedrooms, bathrooms, livingArea
â”œâ”€â”€ address, city, state, zipcode
â”œâ”€â”€ latitude, longitude
â”œâ”€â”€ country (USA/CAN)
â”œâ”€â”€ currency (USD/CAD)
â”œâ”€â”€ ... (all existing fields)

Status Tracking (NEW):
â”œâ”€â”€ status (enum)
â”‚   â”œâ”€â”€ 'just_listed'   - First time seen
â”‚   â”œâ”€â”€ 'active'        - Still available
â”‚   â”œâ”€â”€ 'price_changed' - Price updated
â”‚   â”œâ”€â”€ 'sold'          - No longer available
â”‚   â””â”€â”€ 'off_market'    - Temporarily removed
â”‚
â”œâ”€â”€ first_seen_at (timestamp)
â”‚   â””â”€â”€ When listing was first discovered
â”‚
â”œâ”€â”€ last_seen_at (timestamp)
â”‚   â””â”€â”€ Last scrape where it appeared
â”‚
â”œâ”€â”€ last_updated_at (timestamp)
â”‚   â””â”€â”€ When any data changed
â”‚
â”œâ”€â”€ removed_at (timestamp)
â”‚   â””â”€â”€ When it disappeared from listings
â”‚
â”œâ”€â”€ previous_price (numeric)
â”‚   â””â”€â”€ Price before last change
â”‚
â”œâ”€â”€ price_change_date (timestamp)
â”‚   â””â”€â”€ When price last changed
â”‚
â””â”€â”€ days_on_market (computed)
    â””â”€â”€ Days between first_seen_at and removed_at/now
```

---

## ğŸ”„ THE SCRAPING LOGIC

### **On Each Scrape Run:**

```javascript
for each scraped listing:

  1. Check if zpid exists in database

  2. IF NOT EXISTS:
     INSERT new row
     - status = 'just_listed'
     - first_seen_at = NOW()
     - last_seen_at = NOW()
     - All listing data

  3. IF EXISTS:
     Compare current data with database

     3a. IF price changed:
         UPDATE
         - previous_price = old price
         - price = new price
         - status = 'price_changed'
         - price_change_date = NOW()
         - last_seen_at = NOW()

     3b. IF other data changed:
         UPDATE
         - Changed fields
         - last_updated_at = NOW()
         - last_seen_at = NOW()

     3c. IF nothing changed:
         UPDATE
         - last_seen_at = NOW()
         - status = 'active'

4. AFTER scrape completes:
   Find listings NOT seen in this scrape
   (last_seen_at < scrape_start_time)

   UPDATE those listings
   - status = 'sold' OR 'off_market'
   - removed_at = NOW()
```

---

## ğŸ“ˆ BENEFITS

âœ… **Single Source of Truth**
   - One table, all data
   - No duplication

âœ… **Easy Queries**
   ```sql
   -- All active listings
   SELECT * FROM listings WHERE status IN ('active', 'just_listed', 'price_changed')

   -- Just listed in last 7 days
   SELECT * FROM listings WHERE status = 'just_listed' AND first_seen_at > NOW() - INTERVAL '7 days'

   -- Recently sold
   SELECT * FROM listings WHERE status = 'sold' AND removed_at > NOW() - INTERVAL '7 days'

   -- Price changes
   SELECT * FROM listings WHERE status = 'price_changed' ORDER BY price_change_date DESC
   ```

âœ… **Automatic History**
   - Track entire lifecycle
   - Know exactly when things changed

âœ… **Scalable**
   - Works for 100 cities or 10,000 cities
   - Indexes handle performance

âœ… **Simple Logic**
   - No complex diffs
   - Just upsert with status tracking

---

## ğŸš€ MIGRATION STEPS

### **Step 1: Create New Table**
```sql
CREATE TABLE listings_new (
  -- All existing columns from current_listings
  zpid BIGINT PRIMARY KEY,
  price TEXT,
  unformattedprice NUMERIC,
  bedrooms INT,
  bathrooms INT,
  -- ... all other existing fields ...

  -- NEW status tracking columns
  status TEXT DEFAULT 'active',
  first_seen_at TIMESTAMP DEFAULT NOW(),
  last_seen_at TIMESTAMP DEFAULT NOW(),
  last_updated_at TIMESTAMP DEFAULT NOW(),
  removed_at TIMESTAMP,
  previous_price NUMERIC,
  price_change_date TIMESTAMP,

  -- Indexes for performance
  CREATE INDEX idx_status ON listings_new(status);
  CREATE INDEX idx_first_seen ON listings_new(first_seen_at);
  CREATE INDEX idx_last_seen ON listings_new(last_seen_at);
  CREATE INDEX idx_country ON listings_new(country);
  CREATE INDEX idx_city ON listings_new(city);
);
```

### **Step 2: Migrate Existing Data**
```sql
-- Copy current_listings to new table
INSERT INTO listings_new
SELECT
  *,
  'active' as status,
  lastseenat as first_seen_at,
  lastseenat as last_seen_at,
  lastseenat as last_updated_at,
  NULL as removed_at,
  NULL as previous_price,
  NULL as price_change_date
FROM current_listings;

-- Mark sold listings as sold
UPDATE listings_new
SET status = 'sold', removed_at = NOW()
WHERE zpid IN (SELECT zpid FROM sold_listings);
```

### **Step 3: Update Scraper Logic**
- Modify scraper to use new single-table logic
- Add status tracking on upsert
- Add "mark as sold" after scrape

### **Step 4: Test with Small City**
- Run scraper on one small city
- Verify data integrity
- Check status transitions

### **Step 5: Rename Tables**
```sql
-- Backup old tables
ALTER TABLE current_listings RENAME TO current_listings_backup;
ALTER TABLE previous_listings RENAME TO previous_listings_backup;
ALTER TABLE just_listed RENAME TO just_listed_backup;
ALTER TABLE sold_listings RENAME TO sold_listings_backup;

-- Activate new table
ALTER TABLE listings_new RENAME TO listings;
```

### **Step 6: Update Frontend/Queries**
- Update any queries that reference old tables
- Point to new `listings` table with status filters

### **Step 7: Monitor & Cleanup**
- Run for 1 week
- Verify everything works
- Drop backup tables

---

## ğŸ¯ EMAIL NOTIFICATIONS

**Before:** Query `just_listed` table

**After:** Query `listings WHERE status = 'just_listed'`

**Even Better:**
```sql
-- Just listed today
SELECT * FROM listings
WHERE status = 'just_listed'
AND first_seen_at > NOW() - INTERVAL '24 hours';

-- Price drops
SELECT * FROM listings
WHERE status = 'price_changed'
AND price < previous_price
AND price_change_date > NOW() - INTERVAL '24 hours';
```

---

## ğŸ” SAFETY MEASURES

1. **Backup everything first**
   ```bash
   pg_dump your_database > backup_before_migration.sql
   ```

2. **Keep old tables during migration**
   - Rename, don't drop
   - Keep for 1-2 weeks

3. **Test on small dataset first**
   - Run on 1 city
   - Verify results

4. **Parallel run initially**
   - Write to both old and new tables
   - Compare results
   - Switch when confident

---

## ğŸ“‹ CHECKLIST

- [ ] Review plan
- [ ] Backup current database
- [ ] Create new table schema
- [ ] Migrate existing data
- [ ] Update scraper logic
- [ ] Test with 1 city
- [ ] Compare old vs new results
- [ ] Full migration
- [ ] Update email notifications
- [ ] Update frontend queries
- [ ] Monitor for 1 week
- [ ] Drop old tables

---

## ğŸ¤” QUESTIONS TO ANSWER

1. **Do we migrate all historical data or start fresh?**
   - Migrate: Keeps history but complex
   - Fresh: Clean start, simpler

2. **How long to keep sold listings?**
   - Forever? (full history)
   - 90 days? (recent only)
   - Archive old ones?

3. **Status enum values - are these right?**
   - just_listed
   - active
   - price_changed
   - sold
   - off_market

   Any others needed?

4. **Initial scrape for existing cities?**
   - Mark all as 'active'?
   - Or 'just_listed'?

---

## ğŸ’¬ NEXT STEPS

Once you approve this plan:
1. I'll create the new table schema
2. I'll update the scraper with new logic
3. We'll test on one city
4. Then migrate everything

**Sound good?** Let me know if you want to adjust anything!
